{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5a with feature scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.spatial\n",
    "from scipy.spatial.distance import euclidean\n",
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import sys\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "Data = pd.read_csv(\"BSOM_DataSet_for_HW2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = Data.loc[:,['all_mcqs_avg_n20','CBSE_01']].values\n",
    "X3 = Data.loc[:,['all_mcqs_avg_n20','CBSE_02']].values\n",
    "X4 = Data.loc[:,['all_NBME_avg_n4','CBSE_01']].values\n",
    "X5 = Data.loc[:,['all_NBME_avg_n4','CBSE_02']].values\n",
    "Xmcqs = Data.loc[:,['all_mcqs_avg_n20']].values\n",
    "Xnbme = Data.loc[:,['all_NBME_avg_n4']].values\n",
    "Xcbse1 = Data.loc[:,['CBSE_01']].values\n",
    "Xcbse2 = Data.loc[:,['CBSE_02']].values\n",
    "\n",
    "\n",
    "\n",
    "y= Data.loc[:,['LEVEL']].values\n",
    "train_y, test_y = y[:74,:], y[74:,:]\n",
    "\n",
    "train_X2, test_X2 = X2[:74,:], X2[74:,:]\n",
    "train_X3, test_X3 = X3[:74,:], X3[74:,:]\n",
    "train_X4, test_X4 = X4[:74,:], X4[74:,:]\n",
    "train_X5, test_X5 = X5[:74,:], X5[74:,:]\n",
    "train_N, train_X2_Features = train_X2.shape\n",
    "train_N, train_X3_Features = train_X3.shape\n",
    "train_N, train_X4_Features = train_X4.shape\n",
    "train_N, train_X5_Features = train_X5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsoncorr(X, Y):\n",
    "    covar = np.mean(Y*X)-(np.mean(Y)*np.mean(X))\n",
    "    stddev_1 = np.sqrt(np.mean(Y**2)-(np.mean(Y))**2)\n",
    "    stddev_2 = np.sqrt(np.mean(X**2)-np.mean(X)**2)\n",
    "    corr_coeff = covar/(stddev_1*stddev_2)\n",
    "    print(\"Pearson Correlation Coefficient:\",corr_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B/w mcqs and nbme:\n",
      "Pearson Correlation Coefficient: 0.9022750341290375\n",
      "B/w mcqs and cbse1\n",
      "Pearson Correlation Coefficient: 0.6219946085720189\n",
      "B/w mcqs and cbse2\n",
      "Pearson Correlation Coefficient: 0.7368048779708636\n",
      "B/w nbme and cbse1\n",
      "Pearson Correlation Coefficient: 0.6954437212893951\n",
      "B/w nbme and cbse1\n",
      "Pearson Correlation Coefficient: 0.8134564483193205\n"
     ]
    }
   ],
   "source": [
    "print(\"B/w mcqs and nbme:\")\n",
    "pearsoncorr(Xmcqs,Xnbme)\n",
    "print(\"B/w mcqs and cbse1\")\n",
    "pearsoncorr(Xmcqs,Xcbse1)\n",
    "print(\"B/w mcqs and cbse2\")\n",
    "pearsoncorr(Xmcqs,Xcbse2)\n",
    "print(\"B/w nbme and cbse1\")\n",
    "pearsoncorr(Xnbme,Xcbse1)\n",
    "print(\"B/w nbme and cbse1\")\n",
    "pearsoncorr(Xnbme,Xcbse2)\n",
    "#pearsoncorr(Xnbme,Xcbse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g_of_z= 1/(1+np.exp(-z))\n",
    "    return g_of_z\n",
    "\n",
    "def iteration(y_temp,DataXX,theta):\n",
    "    eta = 0.15\n",
    "    prev_theta = 0\n",
    "    for j in range(10000):\n",
    "        output = DataXX.dot(theta)\n",
    "        h = sigmoid(output)\n",
    "        errors =  sigmoid(output) - y_temp\n",
    "        cost_Fn = (-1/train_N)*np.sum((y_temp*np.log(h))+((1-y_temp)*np.log(1-h)))\n",
    "        prev_theta = theta\n",
    "        derivative = (1/train_N)* DataXX.T.dot(errors)\n",
    "        theta  = theta - (eta * derivative)\n",
    "        if(np.allclose(prev_theta,theta)):\n",
    "            print(\"break theta:\",theta)\n",
    "            break\n",
    "    #hypothesis = sigmoid(DataXX.dot(theta))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: (74, 3)\n",
      "break theta: [[ 3.20008194]\n",
      " [62.57461374]\n",
      " [47.94752177]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in multiply\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypo final: [1 2 0 0 1 2 2 0 2 1 2 1 0 1 1 2 2 1 2 0 1 0 1 0 0 1 1 0 2 2 1 2 0 0 1 2 0\n",
      " 1 1 0 2 1 2 0 2 0 1 2 2 1 2 1 0 1 2 2 0 0 1 0 1 0 1 2 2 0 0 1 2 0 0 0 0 1]\n",
      "hypo final test: [1 0 2 1 1 2 2 2 0 2 1 2 2 2 2 2 1 1 1 2 0 0 2 0 1 1 0 0 1 1 2 2 2 2 2 0 2\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "#mean normalization\n",
    "mean_norm_X = (train_X5-np.mean(train_X5))/(np.max(train_X5)-np.min(train_X5))\n",
    "\n",
    "#minmax_norm_X = (train_X5-np.min(train_X5))/(np.max(train_X5)-np.min(train_X5))\n",
    "DataXX = np.insert(mean_norm_X,0,1,axis=1)\n",
    "print(\"data:\",DataXX.shape)\n",
    "#np.random.seed(233)\n",
    "ttheta =np.random.randint(100,size= (train_X5_Features+1, 1))\n",
    "\n",
    "#A and not B,C,D\n",
    "y = Data.loc[:73,['LEVEL']]\n",
    "level = {'A': 1,'B': 0,'C':0,'D':0} \n",
    "y_copy = [level[item] for item in y.LEVEL]\n",
    "y_copy = np.asarray(y_copy)\n",
    "y_temp = y_copy[:,None]\n",
    "#print(\"y_copy 1:\",y_temp)\n",
    "#print(\"y_copy shape:\",y_temp.shape)\n",
    "theta_ovrA= iteration(y_temp,DataXX,ttheta)\n",
    "hA=sigmoid(DataXX.dot(theta_ovrA))\n",
    "#print(\"hypothesis\",hA)\n",
    "\n",
    "#B and not A,C,D\n",
    "y = Data.loc[:73,['LEVEL']]\n",
    "level = {'A': 0,'B': 1,'C':0,'D':0} \n",
    "y_copy = [level[item] for item in y.LEVEL]\n",
    "y_copy = np.asarray(y_copy)\n",
    "y_temp = y_copy[:,None]\n",
    "theta_ovrB=  iteration(y_temp,DataXX,ttheta)\n",
    "hB=sigmoid(DataXX.dot(theta_ovrB))\n",
    "#print(\"hypoB:\",hB)\n",
    "\n",
    "#C and not A,B,D\n",
    "y = Data.loc[:73,['LEVEL']]\n",
    "level = {'A': 0,'B': 0,'C':1,'D':0} \n",
    "y_copy = [level[item] for item in y.LEVEL]\n",
    "y_copy = np.asarray(y_copy)\n",
    "y_temp = y_copy[:,None]\n",
    "theta_ovrC=  iteration(y_temp,DataXX,ttheta)\n",
    "hC=sigmoid(DataXX.dot(theta_ovrC))\n",
    "#print(\"hypoC:\",hC)\n",
    "\n",
    "#D and not A,B,C\n",
    "y = Data.loc[:73,['LEVEL']]\n",
    "level = {'A': 0,'B': 0,'C':0,'D':1} \n",
    "y_copy= [level[item] for item in y.LEVEL]\n",
    "y_copy = np.asarray(y_copy)\n",
    "y_temp = y_copy[:,None]\n",
    "theta_ovrD=  iteration(y_temp,DataXX,ttheta)\n",
    "hD=sigmoid(DataXX.dot(theta_ovrD))\n",
    "#print(\"hypoD:\",hD)\n",
    "\n",
    "concat_hypo  = np.hstack([hA, hB, hC,hD])\n",
    "#print(\"hypo final:\",concat_hypo )\n",
    "#Return index of max values\n",
    "hypo_final = np.argmax(concat_hypo,axis =1)\n",
    "print(\"hypo final:\",hypo_final )\n",
    "\n",
    "mean_norm_testX = (test_X5-np.mean(test_X5))/(np.max(test_X5)-np.min(test_X5))\n",
    "#minmax_norm_X = (test_X5-np.min(test_X5))/(np.max(test_X5)-np.min(test_X5))\n",
    "testDataXX = np.insert(mean_norm_testX,0,1,axis=1)\n",
    "test_hA=sigmoid(testDataXX.dot(theta_ovrA))\n",
    "test_hB=sigmoid(testDataXX.dot(theta_ovrB))\n",
    "test_hC=sigmoid(testDataXX.dot(theta_ovrC))\n",
    "test_hD=sigmoid(testDataXX.dot(theta_ovrD))\n",
    "tconcat_hypo  = np.hstack([test_hA, test_hB, test_hC,test_hD])\n",
    "\n",
    "#Return index of max values\n",
    "y_pred = np.argmax(tconcat_hypo,axis =1)\n",
    "print(\"hypo final test:\",y_pred )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5b with feature scaling metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Data.loc[:,['LEVEL']]\n",
    "level = {'A': 0,'B': 1,'C':2,'D':3} \n",
    "y_copy = [level[item] for item in y.LEVEL]\n",
    "y_copy = np.asarray(y_copy)\n",
    "y_train = y_copy[:74,None]\n",
    "y_test =  y_copy[74:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confu_mat(y_test, y_pred):\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "def recall(y_test, y_pred):\n",
    "    recall_score(y_test, y_pred, average='macro')  \n",
    "def precision(y_test, y_pred):\n",
    "    precision_score(y_test, y_pred, average='macro') \n",
    "    \n",
    "def fscore(y_true, y_pred):\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')  \n",
    "    print(\"F1 macro :\" ,f1_macro)\n",
    "    f1_micro  = f1_score(y_test, y_pred, average='micro')  \n",
    "    print(\"F1 micro :\" ,f1_micro)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')  \n",
    "    print(\"F1 weighted :\" ,f1_weighted)\n",
    "    f1 = f1_score(y_test, y_pred, average=None)\n",
    "    print(\"F1 score :\" ,f1)      \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  0  0  0]\n",
      " [11  2  7  0]\n",
      " [ 4  3  2  0]\n",
      " [ 2  0  0  0]]\n",
      "F1 macro : 0.20845878136200716\n",
      "F1 micro : 0.2894736842105263\n",
      "F1 weighted : 0.2200339558573854\n",
      "F1 score : [0.4516129  0.16       0.22222222 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "confu_mat(y_test, y_pred)\n",
    "precision(y_test, y_pred)\n",
    "recall(y_test, y_pred)\n",
    "fscore(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.62      0.71      0.67         7\n",
      "          B       0.75      0.45      0.56        20\n",
      "          C       0.44      0.89      0.59         9\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.62      0.58      0.56        38\n",
      "\n",
      "Accuracy: 0.5789473684210527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['A', 'B', 'C','D']))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5a with Feature scaling and Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g_of_z= 1/(1+np.exp(-z))\n",
    "    return g_of_z\n",
    "\n",
    "def iterationr(y_temp,DataXX,theta,lamda):\n",
    "    eta = 0.01\n",
    "    prev_theta = 0\n",
    "    \n",
    "    for j in range(10000):\n",
    "        output = DataXX.dot(theta)\n",
    "        h = sigmoid(output)\n",
    "        \n",
    "        cost_Fn = (-1/train_N)*np.sum((y_temp*np.log(h))+((1-y_temp)*np.log(1-h)))+ lamda/(2*train_N) * sum(np.linalg.norm(theta,1,axis=0))\n",
    "        prev_theta = theta\n",
    "        derivative =  DataXX.T.dot(h-y_temp)\n",
    "        theta  = theta - (eta/train_N * derivative + theta*(lamda/train_N))\n",
    "        theta[0] = theta[0] - (eta/train_N)* DataXX.T.dot(h - y_temp)[0]\n",
    "        \n",
    "        #print(\"theta:\",  theta[0])\n",
    "        if(np.allclose(prev_theta,theta)):\n",
    "            print(\"break theta:\",theta,j)\n",
    "            break\n",
    "    #hypothesis = DataXX.dot(theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break theta: [[-4.02637317]\n",
      " [42.85729229]\n",
      " [46.84644326]] 4925\n",
      "break theta: [[-8.95344854]\n",
      " [43.77197588]\n",
      " [44.2218354 ]] 5718\n",
      "hypo final for lambda  0.0001 : [1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1]\n",
      "hypo final test for lambda  0.0001 : [1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "[[ 5  2  0  0]\n",
      " [ 1 19  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  2  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.83      0.71      0.77         7\n",
      "          B       0.59      0.95      0.73        20\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.47      0.63      0.53        38\n",
      "\n",
      "Accuracy: 0.631578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypo final for lambda  0.001 : [1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1]\n",
      "hypo final test for lambda  0.001 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "[[ 3  4  0  0]\n",
      " [ 1 19  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  2  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.75      0.43      0.55         7\n",
      "          B       0.56      0.95      0.70        20\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.43      0.58      0.47        38\n",
      "\n",
      "Accuracy: 0.5789473684210527\n",
      "hypo final for lambda  0.01 : [1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1]\n",
      "hypo final test for lambda  0.01 : [1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "[[ 5  2  0  0]\n",
      " [ 1 19  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  2  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.83      0.71      0.77         7\n",
      "          B       0.59      0.95      0.73        20\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.47      0.63      0.53        38\n",
      "\n",
      "Accuracy: 0.631578947368421\n",
      "break theta: [[-0.57868018]\n",
      " [ 0.11630148]\n",
      " [ 0.16233786]] 7980\n",
      "break theta: [[-0.41007159]\n",
      " [ 0.08138671]\n",
      " [-0.13084536]] 8241\n",
      "break theta: [[-0.58041826]\n",
      " [ 0.11355532]\n",
      " [-0.29254935]] 7998\n",
      "break theta: [[-1.53134529]\n",
      " [ 0.303254  ]\n",
      " [-0.33603226]] 7280\n",
      "hypo final for lambda  0.1 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "hypo final test for lambda  0.1 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "[[ 1  6  0  0]\n",
      " [ 0 20  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  2  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       1.00      0.14      0.25         7\n",
      "          B       0.54      1.00      0.70        20\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.47      0.55      0.42        38\n",
      "\n",
      "Accuracy: 0.5526315789473685\n",
      "break theta: [[-0.45141306]\n",
      " [ 0.08978827]\n",
      " [ 0.05015232]] 4557\n",
      "break theta: [[-0.34813839]\n",
      " [ 0.06879112]\n",
      " [-0.0939455 ]] 4438\n",
      "break theta: [[-0.50027519]\n",
      " [ 0.09803258]\n",
      " [-0.18851276]] 4309\n",
      "break theta: [[-1.18832881]\n",
      " [ 0.23450842]\n",
      " [-0.25143785]] 3989\n",
      "hypo final for lambda  0.2 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "hypo final test for lambda  0.2 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "[[ 0  7  0  0]\n",
      " [ 0 20  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  2  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.00      0.00      0.00         7\n",
      "          B       0.53      1.00      0.69        20\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.28      0.53      0.36        38\n",
      "\n",
      "Accuracy: 0.5263157894736842\n",
      "break theta: [[-0.18517252]\n",
      " [ 0.0365926 ]\n",
      " [-0.00854676]] 1154\n",
      "break theta: [[-0.15372912]\n",
      " [ 0.03027171]\n",
      " [-0.03547515]] 1061\n",
      "break theta: [[-0.2227492 ]\n",
      " [ 0.04369872]\n",
      " [-0.06210975]] 1035\n",
      "break theta: [[-0.47963936]\n",
      " [ 0.09439055]\n",
      " [-0.09814319]] 982\n",
      "hypo final for lambda  1 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "hypo final test for lambda  1 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "[[ 0  7  0  0]\n",
      " [ 0 20  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  2  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.00      0.00      0.00         7\n",
      "          B       0.53      1.00      0.69        20\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.28      0.53      0.36        38\n",
      "\n",
      "Accuracy: 0.5263157894736842\n",
      "break theta: [[-0.02497333]\n",
      " [ 0.0049287 ]\n",
      " [-0.00212643]] 133\n",
      "break theta: [[-0.02109108]\n",
      " [ 0.00414998]\n",
      " [-0.00468082]] 128\n",
      "break theta: [[-0.03066332]\n",
      " [ 0.00601705]\n",
      " [-0.00787522]] 126\n",
      "break theta: [[-0.0652092 ]\n",
      " [ 0.01282532]\n",
      " [-0.01322924]] 122\n",
      "hypo final for lambda  10 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "hypo final test for lambda  10 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      "[[ 0  7  0  0]\n",
      " [ 0 20  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  2  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.00      0.00      0.00         7\n",
      "          B       0.53      1.00      0.69        20\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.28      0.53      0.36        38\n",
      "\n",
      "Accuracy: 0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#mean normalization\n",
    "mean_norm_X = (train_X5-np.mean(train_X5))/(np.max(train_X5)-np.min(train_X5))\n",
    "\n",
    "DataXX = np.insert(mean_norm_X,0,1,axis=1)\n",
    "#np.random.seed(233)\n",
    "ttheta =np.random.randint(100,size= (train_X_Features+1, 1))\n",
    "\n",
    "\n",
    "lamda = [0.0001,0.001,0.01,0.1,0.2,1,10]\n",
    "for l in lamda:\n",
    "    #A and not B,C,D\n",
    "    y = Data.loc[:73,['LEVEL']]\n",
    "    level = {'A': 1,'B': 0,'C':0,'D':0} \n",
    "    y_copy = [level[item] for item in y.LEVEL]\n",
    "    y_copy = np.asarray(y_copy)\n",
    "    y_temp = y_copy[:,None]\n",
    "    #print(\"y_copy 1:\",y_temp)\n",
    "    #print(\"y_copy shape:\",y_temp.shape)\n",
    "    theta_ovrA= iterationr(y_temp,DataXX,ttheta,l)\n",
    "    hA=sigmoid(DataXX.dot(theta_ovrA))\n",
    "    #print(\"hypothesis\",hA)\n",
    "\n",
    "    #B and not A,C,D\n",
    "    y = Data.loc[:73,['LEVEL']]\n",
    "    level = {'A': 0,'B': 1,'C':0,'D':0} \n",
    "    y_copy = [level[item] for item in y.LEVEL]\n",
    "    y_copy = np.asarray(y_copy)\n",
    "    y_temp = y_copy[:,None]\n",
    "    theta_ovrB=  iterationr(y_temp,DataXX,ttheta,l)\n",
    "    hB=sigmoid(DataXX.dot(theta_ovrB))\n",
    "    #print(\"hypoB:\",hB)\n",
    "\n",
    "    #C and not A,B,D\n",
    "    y = Data.loc[:73,['LEVEL']]\n",
    "    level = {'A': 0,'B': 0,'C':1,'D':0} \n",
    "    y_copy = [level[item] for item in y.LEVEL]\n",
    "    y_copy = np.asarray(y_copy)\n",
    "    y_temp = y_copy[:,None]\n",
    "    theta_ovrC=  iterationr(y_temp,DataXX,ttheta,l)\n",
    "    hC=sigmoid(DataXX.dot(theta_ovrC))\n",
    "    #print(\"hypoC:\",hC)\n",
    "\n",
    "    #D and not A,B,C\n",
    "    y = Data.loc[:73,['LEVEL']]\n",
    "    level = {'A': 0,'B': 0,'C':0,'D':1} \n",
    "    y_copy= [level[item] for item in y.LEVEL]\n",
    "    y_copy = np.asarray(y_copy)\n",
    "    y_temp = y_copy[:,None]\n",
    "    theta_ovrD=  iterationr(y_temp,DataXX,ttheta,l)\n",
    "    hD=sigmoid(DataXX.dot(theta_ovrD))\n",
    "    #print(\"hypoD:\",hD)\n",
    "\n",
    "    concat_hypo  = np.hstack([hA, hB, hC,hD])\n",
    "\n",
    "    #Return index of max values\n",
    "    hypo_final = np.argmax(concat_hypo,axis =1)\n",
    "    print(\"hypo final for lambda \",l,\":\",hypo_final)\n",
    "    mean_norm_testX = (test_X5-np.mean(test_X5))/(np.max(test_X5)-np.min(test_X5))\n",
    "    testDataXX = np.insert(mean_norm_testX,0,1,axis=1)\n",
    "    test_hA=sigmoid(testDataXX.dot(theta_ovrA))\n",
    "    test_hB=sigmoid(testDataXX.dot(theta_ovrB))\n",
    "    test_hC=sigmoid(testDataXX.dot(theta_ovrC))\n",
    "    test_hD=sigmoid(testDataXX.dot(theta_ovrD))\n",
    "    concat_hypo  = np.hstack([test_hA, test_hB, test_hC,test_hD])\n",
    "\n",
    "    #Return index of max values\n",
    "    y_pred = np.argmax(concat_hypo,axis =1)\n",
    "    print(\"hypo final test for lambda \",l,\":\",y_pred)\n",
    "    confu_mat(y_test, y_pred)\n",
    "    precision(y_test, y_pred)\n",
    "    recall(y_test, y_pred)\n",
    "    print(classification_report(y_test, y_pred, target_names=['A', 'B', 'C','D']))\n",
    "    print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
